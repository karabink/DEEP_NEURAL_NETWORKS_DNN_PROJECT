{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqM2XPSafKwj"
      },
      "source": [
        "# Compare the performances of **two** sets of **three** Convolutional Neural Networks\n",
        "*The CNNs in the same set share the same architecture but differ in their training/initialization schema.*\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRM7wVh8uOKK"
      },
      "source": [
        "# Build the Neural Network\n",
        "*(First Set of Components)*\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kJWukn6IPzJ"
      },
      "source": [
        "**Import PyTorch libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ibH9npmLJtkM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms import ToTensor, Compose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvYtpkw5udca"
      },
      "source": [
        "## Get Device for Training\n",
        "We want to be able to train our model on a hardware accelerator like the Graphics Processing Unit (GPU) or Multi-Process Service (MPS), if available. Let's check to see if torch.cuda or torch.backends.mps are available, otherwise we use the Central Processing Unit (CPU).                                                      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bh9GjTuTUR",
        "outputId": "65063f25-cdb2-4f1a-eb8b-5026fc89708b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPJNI_k7KbDx"
      },
      "source": [
        "## Loading a Dataset\n",
        "We load the [MNIST 2-D Dataset](https://pytorch.org/vision/main/datasets.html) with the following parameters:\n",
        "* ```root``` is the path where the train/test data is stored,\n",
        "* ```train``` specifies training or test dataset,\n",
        "* ```transform``` specify the feature and label transformations,\n",
        "* ```download=True``` downloads the data from the internet if it's not available at root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "SyToLohdsxjD"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform=Compose([ToTensor()]),\n",
        "    download=True,\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=Compose([ToTensor()]),\n",
        "    download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKkoWP1Nsp5"
      },
      "source": [
        "## Using DataLoader\n",
        "We create data loaders for training and testing data sets using the DataLoader class, which is responsible for iterating over a data set, providing the ability to batch access data. It takes a data set and batch size as arguments.\n",
        "\n",
        "In our code, the packet size is set to 64, meaning that during training or testing, the data will be divided into packets, and each packet will contain 64 samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "8WcadrCvtCFr"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64) # batch_size is hyperparameter\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For demonstration, we generated a figure showing a grid of 25 randomly selected images from the MNIST training\n",
        "dataset."
      ],
      "metadata": {
        "id": "lpL22PPAwmAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt. figure ( figsize =(7, 5))\n",
        "cols , rows = 5, 5\n",
        "for i in range (1, cols * rows + 1):\n",
        "  sample_idx = torch.randint (len( train_dataset ) , size =(1 ,)). item ()\n",
        "  img , label = train_dataset [ sample_idx ]\n",
        "  fig.add_subplot (rows , cols , i)\n",
        "  plt.title ( label )\n",
        "  plt.axis (\"off\")\n",
        "  plt.imshow (img. squeeze () , cmap ='Blues')\n",
        "  plt.show ()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5dwBffdg09jY",
        "outputId": "dcc15d06-d7ec-4baa-ddcb-40428cf142b4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAKt0lEQVR4nO3dbayXZQHH8etPPJwTDyIPTjEMi3yoQbLAJgscstGiNVHo6UVr5patLXNr9aJe+M6txXKytTZnttq0lT1srCW0DGoFVKZiDpci2kzGPBp4COXhwN2b9qvM2rluzvn/D+d8PptvGL/dF8rh+7+P20WnaZqmAEApZVKvDwDA2CEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgwYe3cubN0Op03/GfPnj29Ph70xOReHwB67dZbby0rVqz4jx9bvHhxj04DvSUKTHirVq0qmzZt6vUxYEzw7SMopRw9erQMDQ31+hjQc6LAhHfTTTeVWbNmlb6+vrJmzZry8MMP9/pI0DO+fcSENXXq1LJx48ayfv36Mm/evLJv376yefPmsmrVqrJr166ybNmyXh8Ruq7jL9mBf9m/f39ZunRpWb16ddm2bVuvjwNd59tH8G8WL15crr/++rJjx45y+vTpXh8Huk4U4HUWLlxYTp48WY4dO9bro0DXiQK8zoEDB0pfX1+ZMWNGr48CXScKTFgDAwP/9WN79+4tW7duLevWrSuTJvnyYOLxP5qZsK677rrS399fVq5cWS644IKyb9++cvfdd5cpU6aU3bt3lyuvvLLXR4SuEwUmrC1btpT77ruv7N+/vwwODpb58+eXtWvXlttvv901F0xYogBA+KYpACEKAIQoABCiAECIAgAhCgDEsK/OPu7vHwE4p/UN4098bwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMTkXh+Ac9Mrr56q3iy6YXO7hx0+WD1Ze8snqjc/vPnq6g2MN94UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAMKFeLSy85kX60dHDrV7WKf+s8sfH3m+/jnj8EK8YyeGqjc/eeKF6s3PnnipevPgj35bvSmllJkXXVi9eXLLjdWb6dMm5h+P3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYmLe+MRZ+/w3d/f6CCPujoee6spzHn9+sCvPKaWUn297vHrTPLt3FE4yco4ePli9OTm0oXozfVr1ZFzwpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAdJqmaYbzE48PjfZROJecf/Xn6kedMf4ZpDlTvxnrv6aLLqueXLNuWfXmk9e8pXrznd1/rd6UUsqdG5ZUby5fMLPVs8abvmHciz3Gf0cD0E2iAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAMQwrkdivBsYPFE/Gt49iq/T4sK5ls5bfm31Zvac+kvT5s7tr97csubS6k0ppVwxZ1b1Zukl57V6Vjd8dNklvT4Cb8CbAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC4EI+y48CL9aNOp8Wm3WeQqZcvr948veXG6s2UyT4jga8CAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHAhHuVXzxzp9RH+rztvW129cbkdtOMrB4AQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwS+o4M/jaqerN/d/aPgonGTlXL5jb6yPAhOFNAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciDfOnBo6Uz966S8jf5A30rQ4G9BV3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwoV4lNJp8dmgzeV2bZ5TSvnKg09Wb+66YUn15sLZfdUbGG+8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgBEp2maZjg/8fjQaB+FkXDsRP1/qA/c9ZvqzZ8e2l29KUcO1W/aOn9B9eT9H1tbvfnitW+v3lyxYGb1ppRSpk9zfyVnp28Yv4W8KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEC/Fo5ZVXT1Vvfn1goNWzvr796erNYz/4cf2DmjP1m07956rOpe+uf04pZe26JdWbBz61otWzGJ9ciAdAFVEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACLekwj99+N4/VG9+sf3x+gc9+1j9pqXz3nNt9WbXHR+s3iw4v796Q/e5JRWAKqIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhAvx4CwcO1H/hbHpnt+3etae736/ftScqZ7MuOp91Zunv7GpetM35U3VG86OC/EAqCIKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgQD7rs0JHjrXbv/Mz91ZvmwKP1D+rUf1b89j1fqt5sWHJx9Yaz40I8AKqIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABDDuB4JGEkXzu5rtXvrO+ovkHuuzYV4Lczvn9aV5zD6vCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhAvxKAODJ6o3g6+dqt4snPvm6k0ppUydPL4+u7x8tP7fdymlPLf9pyN8kv9hxpzqyaI500fhIPTC+PpqA+CsiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAuCV1nPnb309Wby7b+LX6B518rX4zc179ppTy5S98qHrz2ZWLqjcHDx+v3vzuhZerN3du/XP1ppRSSqfFZ7jmTPVkwfIV1ZuL5/RXbxibvCkAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoARKdpmmY4P/H40GgfhZEwdLr+ArQdTw1Ubz5y273Vm3LkUP2mpUlvu6p6c+aZR+of1OaSum5atLR68suvbqzeLFs0u3pD9/UN4wrUMf47GoBuEgUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXIhHK6+8eqp6c/P3Hm31rIce2FE/OnywftPUXybY5kK8/ne9t/45pZSPb7iqevPp5QurN5cvmFm94dzgQjwAqogCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEC7EA5ggXIgHQBVRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDoNE3T9PoQAIwN3hQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFACIfwCgTmpeZ+PUIQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_progress (losses , accuracies ):\n",
        " epochs = range (1, len( losses ) + 1)\n",
        "\n",
        " # Plotting losses\n",
        " plt. figure ( figsize =(10, 5))\n",
        " plt. subplot (1, 2, 1)\n",
        " plt. plot (epochs , losses , '-o')\n",
        " plt. xlabel ('Epoch')\n",
        " plt. ylabel ('Loss')\n",
        " plt. title ('Training Loss')\n",
        "\n",
        " # Plotting accuracies\n",
        " plt. subplot (1, 2, 2)\n",
        " plt. plot (epochs , accuracies , '-o')\n",
        " plt. xlabel ('Epoch')\n",
        " plt. ylabel ('Accuracy')\n",
        " plt. title ('Training Accuracy')\n",
        "\n",
        " plt. tight_layout () # Adjust the padding between and around subplots .\n",
        " plt. show ()\n"
      ],
      "metadata": {
        "id": "G4Xjg7ZCImmQ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPdFeYEQKEQp"
      },
      "source": [
        "## Define the Class\n",
        "We define our neural network by subclassing ```nn.Module```, and initialize the neural network layers in ```__init__```,\n",
        "which is run once when an instance of a Dataset object is created. Every ```nn.Module``` subclass implements the operations on input data in the ```forward``` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "WHzcXIaNLm3X"
      },
      "outputs": [],
      "source": [
        "class CNN_A1_(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_A1_, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5) # One convolutional layer with 4 kernels\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(4 * 26 * 26, 10) # A fully connected layer\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1) # A final Softmaxoutput layer\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x) # The convolutional layer\n",
        "    x = self.relu1(x) # Activation ReLU\n",
        "    x = torch.flatten(x, 1) # The torch.flatten() function reshapes a tensor 'x'\n",
        "    x = self.fc1(x) # Use fully connected layer\n",
        "    x = self.relu2(x) # Activation second ReLU\n",
        "    raw_output = self.softmax(x) # Softmax output\n",
        "    return raw_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sev7-VaL1CY"
      },
      "source": [
        "We create an instance of `CNN_A1_`, and move it to the device, and print its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IadssAOZL14I",
        "outputId": "e52d2cd4-e5af-4764-977e-e6a086da19c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_A1_(\n",
            "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (fc1): Linear(in_features=2704, out_features=10, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = CNN_A1_().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7TUqpRmPwUn"
      },
      "source": [
        "\n",
        "We use the `initialization_hf` function to initialize the weights of the specified convolutional neural network (CNN) model using a predefined weight tensor.\n",
        "\n",
        "The pre-defined  tensor called `weights` has a shape of `(4, 1, 3, 3)`, indicating 4 channels, 1 filter, and a filter size of 3x3.\n",
        "The `weights` tensor is reshaped using the `view` method to match the shape expected by the model's convolutional layer.\n",
        "\n",
        "Finally, the weights of the model's first convolutional layer (`model.conv1.weight`) are assigned the reshaped tensor as a `nn.Parameter` object. The `requires_grad=False` argument ensures that these weights are not updated during the training process and remain fixed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "rHRuSyb3xaMc"
      },
      "outputs": [],
      "source": [
        "def initialization_hf(model):\n",
        "    with torch.no_grad():\n",
        "      weights = torch.FloatTensor([[\n",
        "          [1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
        "          [[0, 0, 1], [0, 1, 0], [1, 0, 0]],\n",
        "          [[0, 1, 0], [0, 1, 0], [0, 1, 0]],\n",
        "          [[0, 0, 0], [1, 1, 1], [0, 0, 0]]])\n",
        "\n",
        "    weights = weights.view(4, 1, 3, 3)\n",
        "\n",
        "    model.conv1.weight = nn.Parameter(weights, requires_grad=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "xWcsjgCj4GCr"
      },
      "outputs": [],
      "source": [
        "def initialization_ht(model):\n",
        "    with torch.no_grad():\n",
        "        weights = torch.FloatTensor([[\n",
        "          [1, 0, 0], [0, 1, 0], [0, 0, 1]],\n",
        "          [[0, 0, 1], [0, 1, 0], [1, 0, 0]],\n",
        "          [[0, 1, 0], [0, 1, 0], [0, 1, 0]],\n",
        "          [[0, 0, 0], [1, 1, 1], [0, 0, 0]]])\n",
        "        bias = torch.FloatTensor([0, 0, 0, 0])\n",
        "\n",
        "        weights = weights.view(4, 1, 3, 3)\n",
        "        bias = bias.view(4)\n",
        "\n",
        "        model.conv1.weight = nn.Parameter(weights, requires_grad=True)\n",
        "        model.conv1.bias = nn.Parameter(bias, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "zZ-0uKXg4GCr"
      },
      "outputs": [],
      "source": [
        "def init_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            nn.init.normal_(m.weight.data)\n",
        "            nn.init.normal_(m.bias.data, 0, 1)\n",
        "\n",
        "        torch.save({\"CNN_default_weights\": model.state_dict()}, \"CNN_default_weights.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEvuSBRpXCdI"
      },
      "source": [
        "## Loss Function\n",
        "To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
        "\n",
        "Common loss functions include ```nn.MSELoss``` (Mean Square Error) for regression tasks, and [nn.NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) (Negative Log Likelihood) for classification. [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) combines ```nn.LogSoftmax``` and ```nn.NLLLoss```.\n",
        "\n",
        "We pass our model's output logits to ```nn.CrossEntropyLoss```, which will normalize the logits and compute the prediction error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "uzP1zPyuxb5r"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()  # Initialize the loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdXhdTu7aAzI"
      },
      "source": [
        "We instantiate a CNN model called `cnn1` using the `CNN_A1_` class and initialize its weights using the `initialization_hf` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCCRLo1qyBAC",
        "outputId": "e3b6d279-b48e-4673-d9bc-84fdfbc9bf9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A1_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (fc1): Linear(in_features=2704, out_features=10, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "cnn1 = CNN_A1_()\n",
        "initialization_hf(cnn1)\n",
        "cnn1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hux0byg84GCt",
        "outputId": "01abc02a-f4b8-4e8f-afaf-83ee67e2917f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A1_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (fc1): Linear(in_features=2704, out_features=10, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "cnn2 = CNN_A1_()\n",
        "initialization_ht(cnn2)\n",
        "cnn2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_gjGY-t4GCt",
        "outputId": "00a47ee0-b7fe-4e5a-dc24-a7b5c2f4c41c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A1_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (fc1): Linear(in_features=2704, out_features=10, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "cnn3 = CNN_A1_()\n",
        "initialization_ht(cnn3)\n",
        "cnn3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4c1ikq0bZLn"
      },
      "source": [
        "## Learning Rate\n",
        "Hyperparameter of the number of model parameter updates in each batch/epoch. Smaller values ​​result in slower learning rates, while larger values ​​can cause unpredictable learning behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "3DQfb50EzJ8v"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr4NnOGZfNi2"
      },
      "source": [
        "## Wrapping it up\n",
        "We define `train_loop` that performs the training loop, and `test_loop` that used for evaluating the trained model on a test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "WCCWHFMGy8ee"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Compute prediction and loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  # torch save model with torch.save()\n",
        "  torch.save({'model_weights': model.state_dict()}, 'model.pt')\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4jOeH2LjAa2"
      },
      "source": [
        "We initialize the loss function and optimizer, and pass it to `train_loop` and `test_loop`. The number of epochs to track the model's improving performance is equal to 20 (more is possible, but not too much)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXUqHs-p4GCu"
      },
      "source": [
        "#### 1 Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia-xS6qSy_r7",
        "outputId": "691b4294-0e42-4cce-9add-ebf65fbd0214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.302911  [   64/60000]\n",
            "loss: 2.271461  [ 6464/60000]\n",
            "loss: 2.250852  [12864/60000]\n",
            "loss: 2.275051  [19264/60000]\n",
            "loss: 2.190306  [25664/60000]\n",
            "loss: 2.129449  [32064/60000]\n",
            "loss: 2.089328  [38464/60000]\n",
            "loss: 2.136639  [44864/60000]\n",
            "loss: 2.193471  [51264/60000]\n",
            "loss: 2.068185  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 37.2%, Avg loss: 2.108708 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.149277  [   64/60000]\n",
            "loss: 2.102182  [ 6464/60000]\n",
            "loss: 1.978000  [12864/60000]\n",
            "loss: 2.213117  [19264/60000]\n",
            "loss: 2.081482  [25664/60000]\n",
            "loss: 2.048480  [32064/60000]\n",
            "loss: 2.024920  [38464/60000]\n",
            "loss: 2.080940  [44864/60000]\n",
            "loss: 2.164252  [51264/60000]\n",
            "loss: 2.041754  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 2.084791 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.124024  [   64/60000]\n",
            "loss: 2.082628  [ 6464/60000]\n",
            "loss: 1.948876  [12864/60000]\n",
            "loss: 2.201737  [19264/60000]\n",
            "loss: 2.071115  [25664/60000]\n",
            "loss: 2.036786  [32064/60000]\n",
            "loss: 2.009838  [38464/60000]\n",
            "loss: 2.067636  [44864/60000]\n",
            "loss: 2.151684  [51264/60000]\n",
            "loss: 2.034354  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 2.073813 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.110128  [   64/60000]\n",
            "loss: 2.069769  [ 6464/60000]\n",
            "loss: 1.941706  [12864/60000]\n",
            "loss: 2.190679  [19264/60000]\n",
            "loss: 2.062062  [25664/60000]\n",
            "loss: 2.028173  [32064/60000]\n",
            "loss: 1.997476  [38464/60000]\n",
            "loss: 2.060243  [44864/60000]\n",
            "loss: 2.138865  [51264/60000]\n",
            "loss: 2.028328  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 38.6%, Avg loss: 2.061303 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.093853  [   64/60000]\n",
            "loss: 2.049834  [ 6464/60000]\n",
            "loss: 1.938614  [12864/60000]\n",
            "loss: 2.132785  [19264/60000]\n",
            "loss: 2.028531  [25664/60000]\n",
            "loss: 1.985732  [32064/60000]\n",
            "loss: 1.940260  [38464/60000]\n",
            "loss: 2.029673  [44864/60000]\n",
            "loss: 2.075851  [51264/60000]\n",
            "loss: 1.957451  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 1.981459 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.015137  [   64/60000]\n",
            "loss: 1.973391  [ 6464/60000]\n",
            "loss: 1.864920  [12864/60000]\n",
            "loss: 2.084405  [19264/60000]\n",
            "loss: 1.971495  [25664/60000]\n",
            "loss: 1.905325  [32064/60000]\n",
            "loss: 1.833022  [38464/60000]\n",
            "loss: 1.949350  [44864/60000]\n",
            "loss: 1.994694  [51264/60000]\n",
            "loss: 1.919163  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 1.937937 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.969243  [   64/60000]\n",
            "loss: 1.954603  [ 6464/60000]\n",
            "loss: 1.835645  [12864/60000]\n",
            "loss: 2.059947  [19264/60000]\n",
            "loss: 1.956550  [25664/60000]\n",
            "loss: 1.887623  [32064/60000]\n",
            "loss: 1.817661  [38464/60000]\n",
            "loss: 1.932508  [44864/60000]\n",
            "loss: 1.983935  [51264/60000]\n",
            "loss: 1.908782  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 1.927672 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.959266  [   64/60000]\n",
            "loss: 1.949024  [ 6464/60000]\n",
            "loss: 1.826197  [12864/60000]\n",
            "loss: 2.051667  [19264/60000]\n",
            "loss: 1.948712  [25664/60000]\n",
            "loss: 1.880304  [32064/60000]\n",
            "loss: 1.810667  [38464/60000]\n",
            "loss: 1.922680  [44864/60000]\n",
            "loss: 1.973572  [51264/60000]\n",
            "loss: 1.889497  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.4%, Avg loss: 1.889518 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.902581  [   64/60000]\n",
            "loss: 1.861922  [ 6464/60000]\n",
            "loss: 1.815737  [12864/60000]\n",
            "loss: 1.965640  [19264/60000]\n",
            "loss: 1.909486  [25664/60000]\n",
            "loss: 1.837377  [32064/60000]\n",
            "loss: 1.717244  [38464/60000]\n",
            "loss: 1.834349  [44864/60000]\n",
            "loss: 1.896792  [51264/60000]\n",
            "loss: 1.808488  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.9%, Avg loss: 1.845806 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.858117  [   64/60000]\n",
            "loss: 1.830579  [ 6464/60000]\n",
            "loss: 1.800315  [12864/60000]\n",
            "loss: 1.953758  [19264/60000]\n",
            "loss: 1.901492  [25664/60000]\n",
            "loss: 1.826389  [32064/60000]\n",
            "loss: 1.706169  [38464/60000]\n",
            "loss: 1.818146  [44864/60000]\n",
            "loss: 1.889921  [51264/60000]\n",
            "loss: 1.800846  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.3%, Avg loss: 1.837838 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.852042  [   64/60000]\n",
            "loss: 1.823023  [ 6464/60000]\n",
            "loss: 1.792931  [12864/60000]\n",
            "loss: 1.948758  [19264/60000]\n",
            "loss: 1.897937  [25664/60000]\n",
            "loss: 1.821124  [32064/60000]\n",
            "loss: 1.700534  [38464/60000]\n",
            "loss: 1.809257  [44864/60000]\n",
            "loss: 1.885910  [51264/60000]\n",
            "loss: 1.796275  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.5%, Avg loss: 1.832976 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.847857  [   64/60000]\n",
            "loss: 1.818514  [ 6464/60000]\n",
            "loss: 1.787901  [12864/60000]\n",
            "loss: 1.945341  [19264/60000]\n",
            "loss: 1.895381  [25664/60000]\n",
            "loss: 1.817928  [32064/60000]\n",
            "loss: 1.696529  [38464/60000]\n",
            "loss: 1.803217  [44864/60000]\n",
            "loss: 1.882908  [51264/60000]\n",
            "loss: 1.793055  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 1.829432 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.844723  [   64/60000]\n",
            "loss: 1.815212  [ 6464/60000]\n",
            "loss: 1.784067  [12864/60000]\n",
            "loss: 1.942739  [19264/60000]\n",
            "loss: 1.893232  [25664/60000]\n",
            "loss: 1.815833  [32064/60000]\n",
            "loss: 1.693367  [38464/60000]\n",
            "loss: 1.798660  [44864/60000]\n",
            "loss: 1.880443  [51264/60000]\n",
            "loss: 1.790584  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.826599 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.842226  [   64/60000]\n",
            "loss: 1.812564  [ 6464/60000]\n",
            "loss: 1.780937  [12864/60000]\n",
            "loss: 1.940647  [19264/60000]\n",
            "loss: 1.891286  [25664/60000]\n",
            "loss: 1.814421  [32064/60000]\n",
            "loss: 1.690756  [38464/60000]\n",
            "loss: 1.794965  [44864/60000]\n",
            "loss: 1.878319  [51264/60000]\n",
            "loss: 1.788591  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.8%, Avg loss: 1.824184 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.840082  [   64/60000]\n",
            "loss: 1.810308  [ 6464/60000]\n",
            "loss: 1.778230  [12864/60000]\n",
            "loss: 1.938859  [19264/60000]\n",
            "loss: 1.889420  [25664/60000]\n",
            "loss: 1.813498  [32064/60000]\n",
            "loss: 1.688531  [38464/60000]\n",
            "loss: 1.791715  [44864/60000]\n",
            "loss: 1.876411  [51264/60000]\n",
            "loss: 1.786931  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 1.821950 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.837875  [   64/60000]\n",
            "loss: 1.808167  [ 6464/60000]\n",
            "loss: 1.775819  [12864/60000]\n",
            "loss: 1.937075  [19264/60000]\n",
            "loss: 1.887443  [25664/60000]\n",
            "loss: 1.812884  [32064/60000]\n",
            "loss: 1.686043  [38464/60000]\n",
            "loss: 1.787583  [44864/60000]\n",
            "loss: 1.873750  [51264/60000]\n",
            "loss: 1.785516  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.5%, Avg loss: 1.815064 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.827706  [   64/60000]\n",
            "loss: 1.787049  [ 6464/60000]\n",
            "loss: 1.779849  [12864/60000]\n",
            "loss: 1.904454  [19264/60000]\n",
            "loss: 1.842945  [25664/60000]\n",
            "loss: 1.730393  [32064/60000]\n",
            "loss: 1.680237  [38464/60000]\n",
            "loss: 1.754397  [44864/60000]\n",
            "loss: 1.819615  [51264/60000]\n",
            "loss: 1.783756  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.7%, Avg loss: 1.770756 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.761580  [   64/60000]\n",
            "loss: 1.741449  [ 6464/60000]\n",
            "loss: 1.772985  [12864/60000]\n",
            "loss: 1.894113  [19264/60000]\n",
            "loss: 1.774915  [25664/60000]\n",
            "loss: 1.709352  [32064/60000]\n",
            "loss: 1.675123  [38464/60000]\n",
            "loss: 1.748920  [44864/60000]\n",
            "loss: 1.807509  [51264/60000]\n",
            "loss: 1.773440  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 1.758998 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.749303  [   64/60000]\n",
            "loss: 1.738860  [ 6464/60000]\n",
            "loss: 1.765774  [12864/60000]\n",
            "loss: 1.890935  [19264/60000]\n",
            "loss: 1.748999  [25664/60000]\n",
            "loss: 1.702924  [32064/60000]\n",
            "loss: 1.672103  [38464/60000]\n",
            "loss: 1.747293  [44864/60000]\n",
            "loss: 1.803676  [51264/60000]\n",
            "loss: 1.768973  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.8%, Avg loss: 1.753506 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.743094  [   64/60000]\n",
            "loss: 1.737573  [ 6464/60000]\n",
            "loss: 1.761345  [12864/60000]\n",
            "loss: 1.889042  [19264/60000]\n",
            "loss: 1.737592  [25664/60000]\n",
            "loss: 1.699074  [32064/60000]\n",
            "loss: 1.669834  [38464/60000]\n",
            "loss: 1.745642  [44864/60000]\n",
            "loss: 1.801506  [51264/60000]\n",
            "loss: 1.766409  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 1.749988 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn1.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn1, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn1, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG4_EH6o4GCu"
      },
      "source": [
        "### 2 Strat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFglNclu4GCu",
        "outputId": "54232707-345c-42c3-9950-8b83a6cb3001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308938  [   64/60000]\n",
            "loss: 2.275506  [ 6464/60000]\n",
            "loss: 2.159400  [12864/60000]\n",
            "loss: 2.093465  [19264/60000]\n",
            "loss: 2.105666  [25664/60000]\n",
            "loss: 2.047309  [32064/60000]\n",
            "loss: 1.975531  [38464/60000]\n",
            "loss: 1.973460  [44864/60000]\n",
            "loss: 1.994943  [51264/60000]\n",
            "loss: 1.897209  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.7%, Avg loss: 1.907669 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.982110  [   64/60000]\n",
            "loss: 1.887056  [ 6464/60000]\n",
            "loss: 1.847401  [12864/60000]\n",
            "loss: 1.899178  [19264/60000]\n",
            "loss: 1.842861  [25664/60000]\n",
            "loss: 1.820821  [32064/60000]\n",
            "loss: 1.821139  [38464/60000]\n",
            "loss: 1.808951  [44864/60000]\n",
            "loss: 1.910057  [51264/60000]\n",
            "loss: 1.796528  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 1.821312 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.893055  [   64/60000]\n",
            "loss: 1.824217  [ 6464/60000]\n",
            "loss: 1.769266  [12864/60000]\n",
            "loss: 1.865280  [19264/60000]\n",
            "loss: 1.788487  [25664/60000]\n",
            "loss: 1.782029  [32064/60000]\n",
            "loss: 1.784858  [38464/60000]\n",
            "loss: 1.759673  [44864/60000]\n",
            "loss: 1.883879  [51264/60000]\n",
            "loss: 1.762478  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 1.792056 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.853914  [   64/60000]\n",
            "loss: 1.800611  [ 6464/60000]\n",
            "loss: 1.739797  [12864/60000]\n",
            "loss: 1.848473  [19264/60000]\n",
            "loss: 1.765294  [25664/60000]\n",
            "loss: 1.765904  [32064/60000]\n",
            "loss: 1.763926  [38464/60000]\n",
            "loss: 1.733266  [44864/60000]\n",
            "loss: 1.862855  [51264/60000]\n",
            "loss: 1.736916  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 1.734763 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.780389  [   64/60000]\n",
            "loss: 1.734246  [ 6464/60000]\n",
            "loss: 1.678168  [12864/60000]\n",
            "loss: 1.803162  [19264/60000]\n",
            "loss: 1.716188  [25664/60000]\n",
            "loss: 1.699458  [32064/60000]\n",
            "loss: 1.658486  [38464/60000]\n",
            "loss: 1.663911  [44864/60000]\n",
            "loss: 1.781444  [51264/60000]\n",
            "loss: 1.705151  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 1.699957 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.741791  [   64/60000]\n",
            "loss: 1.717407  [ 6464/60000]\n",
            "loss: 1.655785  [12864/60000]\n",
            "loss: 1.785867  [19264/60000]\n",
            "loss: 1.693293  [25664/60000]\n",
            "loss: 1.681980  [32064/60000]\n",
            "loss: 1.645216  [38464/60000]\n",
            "loss: 1.646667  [44864/60000]\n",
            "loss: 1.769780  [51264/60000]\n",
            "loss: 1.693948  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.0%, Avg loss: 1.687552 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.725754  [   64/60000]\n",
            "loss: 1.710853  [ 6464/60000]\n",
            "loss: 1.645635  [12864/60000]\n",
            "loss: 1.779425  [19264/60000]\n",
            "loss: 1.680269  [25664/60000]\n",
            "loss: 1.673803  [32064/60000]\n",
            "loss: 1.637242  [38464/60000]\n",
            "loss: 1.636369  [44864/60000]\n",
            "loss: 1.762250  [51264/60000]\n",
            "loss: 1.686916  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 1.679777 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.715123  [   64/60000]\n",
            "loss: 1.706748  [ 6464/60000]\n",
            "loss: 1.639078  [12864/60000]\n",
            "loss: 1.775807  [19264/60000]\n",
            "loss: 1.671710  [25664/60000]\n",
            "loss: 1.668679  [32064/60000]\n",
            "loss: 1.631420  [38464/60000]\n",
            "loss: 1.629044  [44864/60000]\n",
            "loss: 1.756612  [51264/60000]\n",
            "loss: 1.681857  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 1.674166 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.707310  [   64/60000]\n",
            "loss: 1.703783  [ 6464/60000]\n",
            "loss: 1.634213  [12864/60000]\n",
            "loss: 1.773420  [19264/60000]\n",
            "loss: 1.665694  [25664/60000]\n",
            "loss: 1.665048  [32064/60000]\n",
            "loss: 1.626835  [38464/60000]\n",
            "loss: 1.623415  [44864/60000]\n",
            "loss: 1.752092  [51264/60000]\n",
            "loss: 1.677983  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 1.669836 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.701254  [   64/60000]\n",
            "loss: 1.701447  [ 6464/60000]\n",
            "loss: 1.630322  [12864/60000]\n",
            "loss: 1.771701  [19264/60000]\n",
            "loss: 1.661244  [25664/60000]\n",
            "loss: 1.662279  [32064/60000]\n",
            "loss: 1.623057  [38464/60000]\n",
            "loss: 1.618903  [44864/60000]\n",
            "loss: 1.748307  [51264/60000]\n",
            "loss: 1.674909  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 1.666353 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.696401  [   64/60000]\n",
            "loss: 1.699490  [ 6464/60000]\n",
            "loss: 1.627073  [12864/60000]\n",
            "loss: 1.770385  [19264/60000]\n",
            "loss: 1.657791  [25664/60000]\n",
            "loss: 1.660063  [32064/60000]\n",
            "loss: 1.619837  [38464/60000]\n",
            "loss: 1.615185  [44864/60000]\n",
            "loss: 1.745046  [51264/60000]\n",
            "loss: 1.672408  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 1.663468 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.692418  [   64/60000]\n",
            "loss: 1.697779  [ 6464/60000]\n",
            "loss: 1.624280  [12864/60000]\n",
            "loss: 1.769334  [19264/60000]\n",
            "loss: 1.654993  [25664/60000]\n",
            "loss: 1.658223  [32064/60000]\n",
            "loss: 1.617027  [38464/60000]\n",
            "loss: 1.612059  [44864/60000]\n",
            "loss: 1.742178  [51264/60000]\n",
            "loss: 1.670341  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 1.661026 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.689089  [   64/60000]\n",
            "loss: 1.696238  [ 6464/60000]\n",
            "loss: 1.621835  [12864/60000]\n",
            "loss: 1.768470  [19264/60000]\n",
            "loss: 1.652644  [25664/60000]\n",
            "loss: 1.656655  [32064/60000]\n",
            "loss: 1.614525  [38464/60000]\n",
            "loss: 1.609390  [44864/60000]\n",
            "loss: 1.739618  [51264/60000]\n",
            "loss: 1.668607  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 1.658922 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.686264  [   64/60000]\n",
            "loss: 1.694821  [ 6464/60000]\n",
            "loss: 1.619664  [12864/60000]\n",
            "loss: 1.767742  [19264/60000]\n",
            "loss: 1.650616  [25664/60000]\n",
            "loss: 1.655289  [32064/60000]\n",
            "loss: 1.612264  [38464/60000]\n",
            "loss: 1.607083  [44864/60000]\n",
            "loss: 1.737305  [51264/60000]\n",
            "loss: 1.667139  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 1.657086 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.683838  [   64/60000]\n",
            "loss: 1.693499  [ 6464/60000]\n",
            "loss: 1.617718  [12864/60000]\n",
            "loss: 1.767114  [19264/60000]\n",
            "loss: 1.648825  [25664/60000]\n",
            "loss: 1.654080  [32064/60000]\n",
            "loss: 1.610195  [38464/60000]\n",
            "loss: 1.605067  [44864/60000]\n",
            "loss: 1.735194  [51264/60000]\n",
            "loss: 1.665884  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 1.655463 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.681732  [   64/60000]\n",
            "loss: 1.692255  [ 6464/60000]\n",
            "loss: 1.615960  [12864/60000]\n",
            "loss: 1.766563  [19264/60000]\n",
            "loss: 1.647215  [25664/60000]\n",
            "loss: 1.652996  [32064/60000]\n",
            "loss: 1.608285  [38464/60000]\n",
            "loss: 1.603289  [44864/60000]\n",
            "loss: 1.733252  [51264/60000]\n",
            "loss: 1.664803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 1.654015 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.679889  [   64/60000]\n",
            "loss: 1.691079  [ 6464/60000]\n",
            "loss: 1.614361  [12864/60000]\n",
            "loss: 1.766072  [19264/60000]\n",
            "loss: 1.645748  [25664/60000]\n",
            "loss: 1.652013  [32064/60000]\n",
            "loss: 1.606508  [38464/60000]\n",
            "loss: 1.601710  [44864/60000]\n",
            "loss: 1.731453  [51264/60000]\n",
            "loss: 1.663865  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 1.652712 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.678262  [   64/60000]\n",
            "loss: 1.689963  [ 6464/60000]\n",
            "loss: 1.612902  [12864/60000]\n",
            "loss: 1.765627  [19264/60000]\n",
            "loss: 1.644397  [25664/60000]\n",
            "loss: 1.651115  [32064/60000]\n",
            "loss: 1.604843  [38464/60000]\n",
            "loss: 1.600297  [44864/60000]\n",
            "loss: 1.729777  [51264/60000]\n",
            "loss: 1.663046  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 1.651531 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.676816  [   64/60000]\n",
            "loss: 1.688904  [ 6464/60000]\n",
            "loss: 1.611564  [12864/60000]\n",
            "loss: 1.765220  [19264/60000]\n",
            "loss: 1.643140  [25664/60000]\n",
            "loss: 1.650289  [32064/60000]\n",
            "loss: 1.603276  [38464/60000]\n",
            "loss: 1.599025  [44864/60000]\n",
            "loss: 1.728205  [51264/60000]\n",
            "loss: 1.662326  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 1.650452 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.675521  [   64/60000]\n",
            "loss: 1.687899  [ 6464/60000]\n",
            "loss: 1.610333  [12864/60000]\n",
            "loss: 1.764841  [19264/60000]\n",
            "loss: 1.641964  [25664/60000]\n",
            "loss: 1.649523  [32064/60000]\n",
            "loss: 1.601797  [38464/60000]\n",
            "loss: 1.597873  [44864/60000]\n",
            "loss: 1.726724  [51264/60000]\n",
            "loss: 1.661689  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 1.649463 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn2.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn2, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn2, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I4tKsOB4GCu"
      },
      "source": [
        "### 3 Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zweK-iVT4GCu",
        "outputId": "97ed3598-e36b-4a6a-e429-b2a720efe8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299391  [   64/60000]\n",
            "loss: 2.255089  [ 6464/60000]\n",
            "loss: 2.262599  [12864/60000]\n",
            "loss: 2.166980  [19264/60000]\n",
            "loss: 2.133385  [25664/60000]\n",
            "loss: 2.070436  [32064/60000]\n",
            "loss: 2.040009  [38464/60000]\n",
            "loss: 2.077262  [44864/60000]\n",
            "loss: 2.056740  [51264/60000]\n",
            "loss: 1.951091  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.4%, Avg loss: 2.004866 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.034762  [   64/60000]\n",
            "loss: 1.996368  [ 6464/60000]\n",
            "loss: 1.983899  [12864/60000]\n",
            "loss: 1.995948  [19264/60000]\n",
            "loss: 1.982740  [25664/60000]\n",
            "loss: 1.949142  [32064/60000]\n",
            "loss: 1.954796  [38464/60000]\n",
            "loss: 1.928476  [44864/60000]\n",
            "loss: 2.005379  [51264/60000]\n",
            "loss: 1.905734  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.9%, Avg loss: 1.932157 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.993173  [   64/60000]\n",
            "loss: 1.911001  [ 6464/60000]\n",
            "loss: 1.862146  [12864/60000]\n",
            "loss: 1.983288  [19264/60000]\n",
            "loss: 1.929139  [25664/60000]\n",
            "loss: 1.895271  [32064/60000]\n",
            "loss: 1.919678  [38464/60000]\n",
            "loss: 1.877849  [44864/60000]\n",
            "loss: 1.988937  [51264/60000]\n",
            "loss: 1.879948  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.5%, Avg loss: 1.911804 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.972531  [   64/60000]\n",
            "loss: 1.890981  [ 6464/60000]\n",
            "loss: 1.835400  [12864/60000]\n",
            "loss: 1.977478  [19264/60000]\n",
            "loss: 1.918043  [25664/60000]\n",
            "loss: 1.885385  [32064/60000]\n",
            "loss: 1.909720  [38464/60000]\n",
            "loss: 1.860972  [44864/60000]\n",
            "loss: 1.980834  [51264/60000]\n",
            "loss: 1.870491  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.9%, Avg loss: 1.903154 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.962947  [   64/60000]\n",
            "loss: 1.881695  [ 6464/60000]\n",
            "loss: 1.823588  [12864/60000]\n",
            "loss: 1.974970  [19264/60000]\n",
            "loss: 1.912737  [25664/60000]\n",
            "loss: 1.880486  [32064/60000]\n",
            "loss: 1.904685  [38464/60000]\n",
            "loss: 1.851699  [44864/60000]\n",
            "loss: 1.975803  [51264/60000]\n",
            "loss: 1.865579  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.1%, Avg loss: 1.898020 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.957087  [   64/60000]\n",
            "loss: 1.875750  [ 6464/60000]\n",
            "loss: 1.816664  [12864/60000]\n",
            "loss: 1.973491  [19264/60000]\n",
            "loss: 1.909596  [25664/60000]\n",
            "loss: 1.877495  [32064/60000]\n",
            "loss: 1.901619  [38464/60000]\n",
            "loss: 1.845538  [44864/60000]\n",
            "loss: 1.972370  [51264/60000]\n",
            "loss: 1.862523  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.3%, Avg loss: 1.894518 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.952930  [   64/60000]\n",
            "loss: 1.871507  [ 6464/60000]\n",
            "loss: 1.812025  [12864/60000]\n",
            "loss: 1.972448  [19264/60000]\n",
            "loss: 1.907560  [25664/60000]\n",
            "loss: 1.875429  [32064/60000]\n",
            "loss: 1.899567  [38464/60000]\n",
            "loss: 1.841078  [44864/60000]\n",
            "loss: 1.969873  [51264/60000]\n",
            "loss: 1.860391  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.4%, Avg loss: 1.891934 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.949689  [   64/60000]\n",
            "loss: 1.868342  [ 6464/60000]\n",
            "loss: 1.808644  [12864/60000]\n",
            "loss: 1.971627  [19264/60000]\n",
            "loss: 1.906169  [25664/60000]\n",
            "loss: 1.873873  [32064/60000]\n",
            "loss: 1.898108  [38464/60000]\n",
            "loss: 1.837677  [44864/60000]\n",
            "loss: 1.967977  [51264/60000]\n",
            "loss: 1.858790  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.4%, Avg loss: 1.889920 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.947001  [   64/60000]\n",
            "loss: 1.865913  [ 6464/60000]\n",
            "loss: 1.806022  [12864/60000]\n",
            "loss: 1.970921  [19264/60000]\n",
            "loss: 1.905176  [25664/60000]\n",
            "loss: 1.872618  [32064/60000]\n",
            "loss: 1.897025  [38464/60000]\n",
            "loss: 1.834982  [44864/60000]\n",
            "loss: 1.966474  [51264/60000]\n",
            "loss: 1.857523  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.5%, Avg loss: 1.888280 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.944669  [   64/60000]\n",
            "loss: 1.863996  [ 6464/60000]\n",
            "loss: 1.803873  [12864/60000]\n",
            "loss: 1.970276  [19264/60000]\n",
            "loss: 1.904428  [25664/60000]\n",
            "loss: 1.871539  [32064/60000]\n",
            "loss: 1.896194  [38464/60000]\n",
            "loss: 1.832767  [44864/60000]\n",
            "loss: 1.965244  [51264/60000]\n",
            "loss: 1.856467  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.886887 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.942567  [   64/60000]\n",
            "loss: 1.862408  [ 6464/60000]\n",
            "loss: 1.801998  [12864/60000]\n",
            "loss: 1.969638  [19264/60000]\n",
            "loss: 1.903815  [25664/60000]\n",
            "loss: 1.870531  [32064/60000]\n",
            "loss: 1.895526  [38464/60000]\n",
            "loss: 1.830873  [44864/60000]\n",
            "loss: 1.964203  [51264/60000]\n",
            "loss: 1.855538  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.885639 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.940574  [   64/60000]\n",
            "loss: 1.861014  [ 6464/60000]\n",
            "loss: 1.800260  [12864/60000]\n",
            "loss: 1.968942  [19264/60000]\n",
            "loss: 1.903212  [25664/60000]\n",
            "loss: 1.869459  [32064/60000]\n",
            "loss: 1.894937  [38464/60000]\n",
            "loss: 1.829162  [44864/60000]\n",
            "loss: 1.963281  [51264/60000]\n",
            "loss: 1.854668  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 1.884425 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.938530  [   64/60000]\n",
            "loss: 1.859617  [ 6464/60000]\n",
            "loss: 1.798463  [12864/60000]\n",
            "loss: 1.968048  [19264/60000]\n",
            "loss: 1.902445  [25664/60000]\n",
            "loss: 1.868065  [32064/60000]\n",
            "loss: 1.894292  [38464/60000]\n",
            "loss: 1.827475  [44864/60000]\n",
            "loss: 1.962355  [51264/60000]\n",
            "loss: 1.853715  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.883022 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.936064  [   64/60000]\n",
            "loss: 1.857845  [ 6464/60000]\n",
            "loss: 1.796287  [12864/60000]\n",
            "loss: 1.966526  [19264/60000]\n",
            "loss: 1.901095  [25664/60000]\n",
            "loss: 1.865648  [32064/60000]\n",
            "loss: 1.893154  [38464/60000]\n",
            "loss: 1.825564  [44864/60000]\n",
            "loss: 1.960954  [51264/60000]\n",
            "loss: 1.852253  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.7%, Avg loss: 1.880804 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.931974  [   64/60000]\n",
            "loss: 1.854567  [ 6464/60000]\n",
            "loss: 1.793085  [12864/60000]\n",
            "loss: 1.962003  [19264/60000]\n",
            "loss: 1.894264  [25664/60000]\n",
            "loss: 1.835090  [32064/60000]\n",
            "loss: 1.862911  [38464/60000]\n",
            "loss: 1.838175  [44864/60000]\n",
            "loss: 1.895359  [51264/60000]\n",
            "loss: 1.803900  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.6%, Avg loss: 1.822275 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.839185  [   64/60000]\n",
            "loss: 1.749204  [ 6464/60000]\n",
            "loss: 1.755397  [12864/60000]\n",
            "loss: 1.819013  [19264/60000]\n",
            "loss: 1.828475  [25664/60000]\n",
            "loss: 1.803617  [32064/60000]\n",
            "loss: 1.852850  [38464/60000]\n",
            "loss: 1.826730  [44864/60000]\n",
            "loss: 1.868725  [51264/60000]\n",
            "loss: 1.791438  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.1%, Avg loss: 1.811943 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.829152  [   64/60000]\n",
            "loss: 1.741013  [ 6464/60000]\n",
            "loss: 1.746590  [12864/60000]\n",
            "loss: 1.806828  [19264/60000]\n",
            "loss: 1.824427  [25664/60000]\n",
            "loss: 1.800802  [32064/60000]\n",
            "loss: 1.849412  [38464/60000]\n",
            "loss: 1.823489  [44864/60000]\n",
            "loss: 1.856831  [51264/60000]\n",
            "loss: 1.787115  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.4%, Avg loss: 1.807512 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.824586  [   64/60000]\n",
            "loss: 1.738091  [ 6464/60000]\n",
            "loss: 1.742255  [12864/60000]\n",
            "loss: 1.801691  [19264/60000]\n",
            "loss: 1.822196  [25664/60000]\n",
            "loss: 1.798736  [32064/60000]\n",
            "loss: 1.846840  [38464/60000]\n",
            "loss: 1.821908  [44864/60000]\n",
            "loss: 1.849604  [51264/60000]\n",
            "loss: 1.784992  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 1.804672 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.821291  [   64/60000]\n",
            "loss: 1.736328  [ 6464/60000]\n",
            "loss: 1.739305  [12864/60000]\n",
            "loss: 1.798561  [19264/60000]\n",
            "loss: 1.820676  [25664/60000]\n",
            "loss: 1.797116  [32064/60000]\n",
            "loss: 1.844432  [38464/60000]\n",
            "loss: 1.820734  [44864/60000]\n",
            "loss: 1.844541  [51264/60000]\n",
            "loss: 1.783740  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 1.802417 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.818338  [   64/60000]\n",
            "loss: 1.734831  [ 6464/60000]\n",
            "loss: 1.736851  [12864/60000]\n",
            "loss: 1.796107  [19264/60000]\n",
            "loss: 1.819430  [25664/60000]\n",
            "loss: 1.795700  [32064/60000]\n",
            "loss: 1.841741  [38464/60000]\n",
            "loss: 1.819578  [44864/60000]\n",
            "loss: 1.840435  [51264/60000]\n",
            "loss: 1.782816  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 1.800298 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn3.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn3, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn3, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVb1ppDjTCl_"
      },
      "source": [
        "## Define the Class\n",
        "We define our neural network by subclassing ```nn.Module```, and initialize the neural network layers in ```__init__```,\n",
        "which is run once when an instance of a Dataset object is created. Every ```nn.Module``` subclass implements the operations on input data in the ```forward``` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "qLADAdcBTDc_"
      },
      "outputs": [],
      "source": [
        "class CNN_A2_(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_A2_, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3)#filter size 1x5x5\n",
        "    self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3) #filter size 4x3x3x\n",
        "    self.relu = nn.ReLU()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(8*24*24, 10) # A fully connected layer\n",
        "    self.softmax = nn.Softmax(dim=1) # A final Softmax output layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.conv1(x)) # The convolutional layer 1\n",
        "    x = self.relu(self.conv2(x)) # The convolutional layer 2\n",
        "    x = self.flatten(x) # The torch.flatten() function reshapes a tensor 'x'\n",
        "    raw_output = self.softmax(x) # Softmax output\n",
        "\n",
        "    return raw_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ45T-ZfTKgv"
      },
      "source": [
        "We create an instance of `CNN_A2_` , and move it to the device, and print its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "ogwm-FgfTLIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408f17eb-6518-4ccc-c261-04d8645ce8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN_A2_(\n",
            "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (relu): ReLU()\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=4608, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = CNN_A2_().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRp7S20XTLaf"
      },
      "source": [
        "We use the initialization_hf function to initialize the weights of the specified convolutional neural network (CNN) model using a predefined weight tensor.\n",
        "\n",
        "The pre-defined tensor called weights has a shape of (4, 1, 3, 3), indicating 4 channels, 1 filter, and a filter size of 3x3. The weights tensor is reshaped using the view method to match the shape expected by the model's convolutional layer.\n",
        "\n",
        "Finally, the weights of the model's first convolutional layer (model.conv1.weight) are assigned the reshaped tensor as a nn.Parameter object. The requires_grad=False argument ensures that these weights are not updated during the training process and remain fixed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmC6vcyD6nRb"
      },
      "source": [
        "We instantiate a CNN model called `cnn4` using the `CNN_A2_` class and initialize its weights using the `initialization_hf` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "BN0Jebr34GCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373d131b-0d45-4dfa-d882-bf7ae6428473"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A2_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4608, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "cnn4 = CNN_A2_()\n",
        "initialization_hf(cnn4)\n",
        "cnn4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate a CNN model called `cnn5` using the `CNN_A2_` class and initialize its weights using the `initialization_ht` function."
      ],
      "metadata": {
        "id": "uPTGDDxOsyBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "pl5yl5lf4GCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b8bd1a-71b3-4b4d-c49a-00bb979a5336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A2_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4608, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "cnn5 = CNN_A2_()\n",
        "initialization_ht(cnn5)\n",
        "cnn5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We instantiate a CNN model called `cnn6` using the `CNN_A2_` class and  initializes its weights and biases using a custom `init_weights` function."
      ],
      "metadata": {
        "id": "SL4HZK55tF-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "aO-nuICR4GCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a69909-e098-462a-82dc-052edefe11cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_A2_(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4608, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "cnn6 = CNN_A2_()\n",
        "cnn6.apply(init_weights)\n",
        "cnn6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "YQnkXn6uuaXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "CV-LVL6A4GCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d44b9b-4361-43ec-a539-bb378b1273ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435566  [38464/60000]\n",
            "loss: 8.435565  [44864/60000]\n",
            "loss: 8.435569  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435565  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435565  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435565  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435569  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435565  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435567  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435567  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435566  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435565  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435567  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435569  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435565  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435565  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435564  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435568  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435565  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435564  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435565  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 8.435564  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435568  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435564  [38464/60000]\n",
            "loss: 8.435565  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435567  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435564  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 8.435566  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435565  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435566  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435566  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435566  [25664/60000]\n",
            "loss: 8.435565  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 8.435565  [   64/60000]\n",
            "loss: 8.435567  [ 6464/60000]\n",
            "loss: 8.435564  [12864/60000]\n",
            "loss: 8.435567  [19264/60000]\n",
            "loss: 8.435565  [25664/60000]\n",
            "loss: 8.435566  [32064/60000]\n",
            "loss: 8.435565  [38464/60000]\n",
            "loss: 8.435564  [44864/60000]\n",
            "loss: 8.435567  [51264/60000]\n",
            "loss: 8.435566  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435566 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn4.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn4, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn4, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "QtSr3LaS4GC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6809f578-0eb4-41f0-ae8f-28667c56a4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435586  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435590  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435580  [44864/60000]\n",
            "loss: 8.435589  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 8.435584  [   64/60000]\n",
            "loss: 8.435586  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435590  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435586  [32064/60000]\n",
            "loss: 8.435581  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435589  [51264/60000]\n",
            "loss: 8.435582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435586  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435590  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435581  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435590  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435583  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 8.435584  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435590  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435586  [32064/60000]\n",
            "loss: 8.435581  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 8.435584  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435586  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435583  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435586  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435583  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435580  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435583  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435584 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435586  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435583  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435583  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435583  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435580  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435584  [32064/60000]\n",
            "loss: 8.435579  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435580  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435581  [25664/60000]\n",
            "loss: 8.435584  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435579  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435587  [51264/60000]\n",
            "loss: 8.435582  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435579  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435588  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 8.435583  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435579  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435585  [32064/60000]\n",
            "loss: 8.435579  [38464/60000]\n",
            "loss: 8.435579  [44864/60000]\n",
            "loss: 8.435586  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 8.435582  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435579  [25664/60000]\n",
            "loss: 8.435584  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435578  [44864/60000]\n",
            "loss: 8.435586  [51264/60000]\n",
            "loss: 8.435581  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 8.435581  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435578  [12864/60000]\n",
            "loss: 8.435589  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435584  [32064/60000]\n",
            "loss: 8.435580  [38464/60000]\n",
            "loss: 8.435577  [44864/60000]\n",
            "loss: 8.435586  [51264/60000]\n",
            "loss: 8.435580  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 8.435581  [   64/60000]\n",
            "loss: 8.435585  [ 6464/60000]\n",
            "loss: 8.435577  [12864/60000]\n",
            "loss: 8.435588  [19264/60000]\n",
            "loss: 8.435580  [25664/60000]\n",
            "loss: 8.435583  [32064/60000]\n",
            "loss: 8.435579  [38464/60000]\n",
            "loss: 8.435577  [44864/60000]\n",
            "loss: 8.435586  [51264/60000]\n",
            "loss: 8.435580  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435583 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn5.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn5, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn5, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "F8skJ3ad4GC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42eae1b7-9219-4811-ef0e-9a97082804fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435798  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435802  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435813  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435800  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435815  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435799  [ 6464/60000]\n",
            "loss: 8.435803  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435800  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435813  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435798  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 8.435791  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435802  [44864/60000]\n",
            "loss: 8.435813  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435815  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435798  [38464/60000]\n",
            "loss: 8.435802  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435805  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435812  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435802  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 8.435791  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435804  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435797  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435800  [38464/60000]\n",
            "loss: 8.435804  [44864/60000]\n",
            "loss: 8.435813  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435803  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435797  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435813  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435800  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435800  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435802  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435804  [19264/60000]\n",
            "loss: 8.435800  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 8.435789  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435803  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435800  [38464/60000]\n",
            "loss: 8.435804  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435798  [38464/60000]\n",
            "loss: 8.435803  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435803  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 8.435792  [   64/60000]\n",
            "loss: 8.435800  [ 6464/60000]\n",
            "loss: 8.435803  [12864/60000]\n",
            "loss: 8.435802  [19264/60000]\n",
            "loss: 8.435799  [25664/60000]\n",
            "loss: 8.435800  [32064/60000]\n",
            "loss: 8.435798  [38464/60000]\n",
            "loss: 8.435802  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435802  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 8.435790  [   64/60000]\n",
            "loss: 8.435801  [ 6464/60000]\n",
            "loss: 8.435804  [12864/60000]\n",
            "loss: 8.435803  [19264/60000]\n",
            "loss: 8.435800  [25664/60000]\n",
            "loss: 8.435801  [32064/60000]\n",
            "loss: 8.435799  [38464/60000]\n",
            "loss: 8.435804  [44864/60000]\n",
            "loss: 8.435814  [51264/60000]\n",
            "loss: 8.435804  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 0.0%, Avg loss: 8.435800 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn6.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train_loop(train_dataloader, cnn6, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, cnn6, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "X7LN-ziK4GC0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}